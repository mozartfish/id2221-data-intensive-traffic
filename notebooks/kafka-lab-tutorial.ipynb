{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b7ffb7c-b05e-4efc-a098-bf1ad9bf11a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer, KafkaAdminClient\n",
    "from kafka.admin import NewTopic\n",
    "from kafka.errors import TopicAlreadyExistsError\n",
    "import json\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0451e6c3-c6d5-4ca8-b98b-2264116a977f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Kafka topic...\n",
      "Topic 'test' already exists\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Kafka topic...\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "admin_client = KafkaAdminClient(\n",
    "    bootstrap_servers=['localhost:9092'],\n",
    "    client_id='notebook_admin'\n",
    ")\n",
    "\n",
    "topic_name = 'test'\n",
    "topic = NewTopic(\n",
    "    name=topic_name, \n",
    "    num_partitions=1, \n",
    "    replication_factor=1\n",
    ")\n",
    "\n",
    "try:\n",
    "    admin_client.create_topics(new_topics=[topic], validate_only=False)\n",
    "    print(f\"Topic '{topic_name}' created\")\n",
    "except TopicAlreadyExistsError:\n",
    "    print(f\"Topic '{topic_name}' already exists\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "finally:\n",
    "    admin_client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d81cd2-2efd-4ae6-ba5d-7055261947f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent 5 messages\n"
     ]
    }
   ],
   "source": [
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=['localhost:9092'],\n",
    "    value_serializer=lambda v: v.encode('utf-8')\n",
    ")\n",
    "\n",
    "rows = [\n",
    "    \"196,242,3.0,881250949\",\n",
    "    \"186,302,3.0,891717742\",\n",
    "    \"22,377,1.0,878887116\",\n",
    "    \"244,51,2.0,880606923\",\n",
    "    \"166,346,1.0,886397596\",\n",
    "]\n",
    "\n",
    "for line in rows:\n",
    "    producer.send('test', value=line)\n",
    "    \n",
    "producer.flush()\n",
    "producer.close()\n",
    "print(f\"Sent {len(rows)} messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a04e566-3802-4a0c-96df-3ccc9d020181",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/09/29 09:30:41 WARN Utils: Your hostname, Pranavs-MacBook-Pro.local, resolves to a loopback address: 127.0.0.1; using 192.168.0.38 instead (on interface en0)\n",
      "25/09/29 09:30:41 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/Users/pranavrajan/Desktop/id2221-data-intensive-traffic/.venv/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /Users/pranavrajan/.ivy2.5.2/cache\n",
      "The jars for the packages stored in: /Users/pranavrajan/.ivy2.5.2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.13 added as a dependency\n",
      "org.apache.spark#spark-token-provider-kafka-0-10_2.13 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-b0b8aaca-f32e-4953-a26e-c03eff7fd7f3;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.13;4.0.0 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.13;4.0.0 in central\n",
      "\tfound org.apache.kafka#kafka-clients;3.9.0 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.10.7 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.16 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.4.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.4.1 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.scala-lang.modules#scala-parallel-collections_2.13;1.2.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.12.0 in central\n",
      ":: resolution report :: resolve 174ms :: artifacts dl 5ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.12.0 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.4.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.4.1 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;3.9.0 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.13;4.0.0 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.13;4.0.0 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.scala-lang.modules#scala-parallel-collections_2.13;1.2.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.16 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.7 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   11  |   0   |   0   |   0   ||   11  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-b0b8aaca-f32e-4953-a26e-c03eff7fd7f3\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 11 already retrieved (0kB/3ms)\n",
      "25/09/29 09:30:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.38:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>kafka-structured-streaming-local</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10efa0510>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"kafka-structured-streaming-local\")\n",
    "    .config(\n",
    "        \"spark.jars.packages\",\n",
    "        \"org.apache.spark:spark-sql-kafka-0-10_2.13:4.0.0,\"\n",
    "        \"org.apache.spark:spark-token-provider-kafka-0-10_2.13:4.0.0\"\n",
    "    )\n",
    "    .config(\"spark.sql.streaming.forceDeleteTempCheckpointLocation\", \"true\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8fea0e5-1ca6-4efc-86d9-6998e0837bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType, LongType\n",
    "from pyspark.sql.functions import col, from_csv\n",
    "\n",
    "# Schema for the CSV in Kafka 'value'\n",
    "schema_ddl = \"UserId INT, MovieId INT, Rating DOUBLE, Timestamp LONG\"\n",
    "\n",
    "# Read from Kafka\n",
    "raw = (spark.readStream\n",
    "    .format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n",
    "    .option(\"subscribe\", \"test\")\n",
    "    .option(\"startingOffsets\", \"earliest\")\n",
    "    .load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ddb4263-e614-4e88-b8ad-bd0afc9cc739",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = (raw\n",
    "    .selectExpr(\"CAST(value AS STRING) AS value_str\", \"timestamp AS KafkaTimestamp\")\n",
    "    .select(from_csv(col(\"value_str\"), schema_ddl).alias(\"r\"), col(\"KafkaTimestamp\"))\n",
    "    .select(\"r.*\", \"KafkaTimestamp\")\n",
    "    .where(col(\"UserId\").isNotNull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9fcbdbb-79eb-437a-82b6-fd44f55a6a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>MovieId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>KafkaTimestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>881250949</td>\n",
       "      <td>2025-09-29 09:16:37.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "      <td>891717742</td>\n",
       "      <td>2025-09-29 09:16:37.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>878887116</td>\n",
       "      <td>2025-09-29 09:16:37.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>880606923</td>\n",
       "      <td>2025-09-29 09:16:37.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886397596</td>\n",
       "      <td>2025-09-29 09:16:37.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>881250949</td>\n",
       "      <td>2025-09-29 09:22:18.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "      <td>891717742</td>\n",
       "      <td>2025-09-29 09:22:18.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>878887116</td>\n",
       "      <td>2025-09-29 09:22:18.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>880606923</td>\n",
       "      <td>2025-09-29 09:22:18.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886397596</td>\n",
       "      <td>2025-09-29 09:22:18.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>881250949</td>\n",
       "      <td>2025-09-29 09:27:49.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "      <td>891717742</td>\n",
       "      <td>2025-09-29 09:27:49.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>878887116</td>\n",
       "      <td>2025-09-29 09:27:49.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>880606923</td>\n",
       "      <td>2025-09-29 09:27:49.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886397596</td>\n",
       "      <td>2025-09-29 09:27:49.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>881250949</td>\n",
       "      <td>2025-09-29 09:30:40.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "      <td>891717742</td>\n",
       "      <td>2025-09-29 09:30:40.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>878887116</td>\n",
       "      <td>2025-09-29 09:30:40.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>880606923</td>\n",
       "      <td>2025-09-29 09:30:40.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886397596</td>\n",
       "      <td>2025-09-29 09:30:40.933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    UserId  MovieId  Rating  Timestamp          KafkaTimestamp\n",
       "0      196      242     3.0  881250949 2025-09-29 09:16:37.398\n",
       "1      186      302     3.0  891717742 2025-09-29 09:16:37.398\n",
       "2       22      377     1.0  878887116 2025-09-29 09:16:37.398\n",
       "3      244       51     2.0  880606923 2025-09-29 09:16:37.398\n",
       "4      166      346     1.0  886397596 2025-09-29 09:16:37.398\n",
       "5      196      242     3.0  881250949 2025-09-29 09:22:18.646\n",
       "6      186      302     3.0  891717742 2025-09-29 09:22:18.647\n",
       "7       22      377     1.0  878887116 2025-09-29 09:22:18.647\n",
       "8      244       51     2.0  880606923 2025-09-29 09:22:18.647\n",
       "9      166      346     1.0  886397596 2025-09-29 09:22:18.647\n",
       "10     196      242     3.0  881250949 2025-09-29 09:27:49.062\n",
       "11     186      302     3.0  891717742 2025-09-29 09:27:49.062\n",
       "12      22      377     1.0  878887116 2025-09-29 09:27:49.062\n",
       "13     244       51     2.0  880606923 2025-09-29 09:27:49.062\n",
       "14     166      346     1.0  886397596 2025-09-29 09:27:49.062\n",
       "15     196      242     3.0  881250949 2025-09-29 09:30:40.932\n",
       "16     186      302     3.0  891717742 2025-09-29 09:30:40.933\n",
       "17      22      377     1.0  878887116 2025-09-29 09:30:40.933\n",
       "18     244       51     2.0  880606923 2025-09-29 09:30:40.933\n",
       "19     166      346     1.0  886397596 2025-09-29 09:30:40.933"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/29 09:30:59 WARN DAGScheduler: Failed to cancel job group eface530-af6c-49eb-94c1-822bb7c93ce7. Cannot find active jobs for it.\n",
      "25/09/29 09:30:59 WARN DAGScheduler: Failed to cancel job group eface530-af6c-49eb-94c1-822bb7c93ce7. Cannot find active jobs for it.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output, display\n",
    "\n",
    "def show_batch(batch_df, epoch_id):\n",
    "    pdf = batch_df.limit(50).toPandas()\n",
    "    clear_output(wait=True)\n",
    "    if pdf.empty:\n",
    "        print(f\"(epoch {epoch_id}) no rows\")\n",
    "    else:\n",
    "        display(pdf)\n",
    "\n",
    "q = (parsed.writeStream\n",
    "     .foreachBatch(show_batch)\n",
    "     .outputMode(\"append\")\n",
    "     .start())\n",
    "\n",
    "# Keep it alive ~15s so you see output.\n",
    "q.awaitTermination(15)\n",
    "q.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d152ec-f67a-44c3-bc36-48edb6ed586d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
